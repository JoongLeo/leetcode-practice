#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import json
import time
import requests
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timezone, timedelta

class LeetCodeSyncer:
    def __init__(self, sync_after: Optional[str] = None, debug: bool = False):
        """
        åˆå§‹åŒ–åŒæ­¥å™¨
        
        Args:
            sync_after: åªåŒæ­¥æ­¤æ—¶é—´ä¹‹åçš„æäº¤ï¼Œæ ¼å¼: "2026-01-26 23:47" (åŒ—äº¬æ—¶é—´)
            debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        """
        # ä¼˜å…ˆä½¿ç”¨ LeetCode CN
        self.use_cn = bool(os.getenv('LEETCODE_CN_SESSION'))
        
        if self.use_cn:
            self.base_url = "https://leetcode.cn"
            self.session_cookie = os.getenv('LEETCODE_CN_SESSION')
            self.csrf_token = os.getenv('LEETCODE_CN_CSRF_TOKEN')
            print("âœ… ä½¿ç”¨ LeetCode CN")
        else:
            self.base_url = "https://leetcode.com"
            self.session_cookie = os.getenv('LEETCODE_SESSION')
            self.csrf_token = os.getenv('LEETCODE_CSRF_TOKEN')
            print("âœ… ä½¿ç”¨ LeetCode Global")
        
        if not self.session_cookie:
            raise ValueError("âŒ æœªæ‰¾åˆ° LeetCode Session Cookieï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡")
        
        self.session = requests.Session()
        self.session.cookies.set('LEETCODE_SESSION', self.session_cookie)
        if self.csrf_token:
            self.session.cookies.set('csrftoken', self.csrf_token)
        
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': self.base_url,
            'Origin': self.base_url,
            'Accept': 'application/json',
        })
        
        if self.csrf_token:
            self.session.headers['X-CSRFToken'] = self.csrf_token
        
        self.synced_file = Path('.synced_submissions.json')
        self.synced_ids = self.load_synced_ids()
        self.debug = debug
        
        if debug:
            print("ğŸ› è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
        
        # è®¾ç½®æ—¶é—´è¿‡æ»¤
        self.sync_after_timestamp = self._parse_sync_after_time(sync_after)
        if self.sync_after_timestamp:
            dt = datetime.fromtimestamp(self.sync_after_timestamp, tz=timezone(timedelta(hours=8)))
            print(f"â° åªåŒæ­¥ {dt.strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´) ä¹‹åçš„æäº¤")
    
    def _parse_sync_after_time(self, time_str: Optional[str]) -> Optional[int]:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸º Unix æ—¶é—´æˆ³"""
        if not time_str:
            return self._get_last_sync_time()
        
        try:
            dt = datetime.strptime(time_str, "%Y-%m-%d %H:%M")
            dt = dt.replace(tzinfo=timezone(timedelta(hours=8)))
            return int(dt.timestamp())
        except Exception as e:
            print(f"âš ï¸  æ—¶é—´æ ¼å¼è§£æå¤±è´¥ '{time_str}': {e}")
            return None
    
    def _get_last_sync_time(self) -> Optional[int]:
        """ä»é…ç½®æ–‡ä»¶è·å–ä¸Šæ¬¡åŒæ­¥æ—¶é—´"""
        if self.synced_file.exists():
            try:
                with open(self.synced_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    last_sync = data.get('last_sync')
                    if last_sync:
                        dt = datetime.fromisoformat(last_sync)
                        print(f"ğŸ“… ä¸Šæ¬¡åŒæ­¥æ—¶é—´: {data.get('last_sync_beijing', 'Unknown')}")
                        return int(dt.timestamp())
            except:
                pass
        return None
    
    def load_synced_ids(self) -> set:
        """åŠ è½½å·²åŒæ­¥çš„æäº¤ID"""
        if self.synced_file.exists():
            try:
                with open(self.synced_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    synced_ids = set(data.get('synced_ids', []))
                    if synced_ids:
                        print(f"ğŸ“¦ å·²åŠ è½½ {len(synced_ids)} æ¡åŒæ­¥è®°å½•")
                    return synced_ids
            except:
                return set()
        return set()
    
    def save_synced_ids(self):
        """ä¿å­˜å·²åŒæ­¥çš„æäº¤ID"""
        with open(self.synced_file, 'w', encoding='utf-8') as f:
            json.dump({
                'synced_ids': list(self.synced_ids),
                'last_sync': datetime.now().isoformat(),
                'last_sync_beijing': datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')
            }, f, indent=2, ensure_ascii=False)
    
    def get_ac_submissions(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ACçš„æäº¤è®°å½•"""
        print("ğŸ” æ­£åœ¨è·å–ACæäº¤è®°å½•...")
        
        url = f"{self.base_url}/api/submissions/"
        params = {'offset': 0, 'limit': 20, 'lastkey': ''}
        
        all_submissions = []
        seen_ids = set()
        page = 0
        
        while True:
            try:
                page += 1
                if self.debug:
                    print(f"  ğŸ“„ è·å–ç¬¬ {page} é¡µ...")
                
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 403:
                    print(f"âš ï¸  è¯·æ±‚è¢«é™åˆ¶ (403)ï¼Œç­‰å¾…5ç§’...")
                    time.sleep(5)
                    continue
                
                response.raise_for_status()
                data = response.json()
                
                submissions = data.get('submissions_dump', [])
                if not submissions:
                    break
                
                should_stop = False
                for sub in submissions:
                    sub_id = sub.get('id')
                    timestamp = sub.get('timestamp')
                    
                    # æ—¶é—´è¿‡æ»¤
                    if self.sync_after_timestamp and timestamp:
                        if int(timestamp) < self.sync_after_timestamp:
                            should_stop = True
                            break
                    
                    if sub.get('status_display') == 'Accepted' and sub_id not in seen_ids:
                        seen_ids.add(sub_id)
                        all_submissions.append(sub)
                
                if should_stop:
                    print(f"â¹ï¸  å·²åˆ°è¾¾æ—¶é—´æˆªæ­¢ç‚¹ï¼Œåœæ­¢è·å–")
                    break
                
                if not data.get('has_next', False):
                    break
                
                params['offset'] += params['limit']
                params['lastkey'] = submissions[-1].get('id', '')
                time.sleep(1)
                
            except Exception as e:
                print(f"âŒ è·å–æäº¤è®°å½•å‡ºé”™: {e}")
                break
        
        print(f"âœ… å…±è·å–åˆ° {len(all_submissions)} æ¡ACæäº¤è®°å½•")
        return all_submissions
    
    def get_submission_detail(self, submission_id: int) -> Optional[Dict]:
        """è·å–æäº¤è¯¦æƒ…ï¼ˆåŒ…å«ä»£ç ï¼‰"""
        url = f"{self.base_url}/api/submissions/{submission_id}/"
        
        for retry in range(3):
            try:
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                return response.json()
            except Exception as e:
                if retry < 2:
                    time.sleep(2)
                    continue
                if self.debug:
                    print(f"  âŒ è·å–è¯¦æƒ…å¤±è´¥: {e}")
                return None
    
    def has_valid_comment(self, code: str) -> bool:
        """æ£€æŸ¥ä»£ç æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„ç›®å½•ç»“æ„æ³¨é‡Š"""
        if not code:
            return False
        
        lines = code.strip().split('\n')
        
        # è‡³å°‘éœ€è¦2è¡Œæ³¨é‡Šï¼ˆ1ä¸ªç›®å½• + æ–‡ä»¶åï¼‰
        if len(lines) < 2:
            return False
        
        if self.debug:
            print(f"  ğŸ“ ä»£ç å‰10è¡Œ:")
            for i in range(min(10, len(lines))):
                print(f"     {i+1}: {lines[i][:100]}")
        
        # æ£€æµ‹æ³¨é‡Šç±»å‹
        comment_prefix = None
        if lines[0].strip().startswith('//'):
            comment_prefix = '//'
        elif lines[0].strip().startswith('#'):
            comment_prefix = '#'
        else:
            if self.debug:
                print(f"  âŒ ç¬¬ä¸€è¡Œä¸æ˜¯æ³¨é‡Š")
            return False
        
        # æ”¶é›†è¿ç»­çš„æ³¨é‡Šè¡Œ
        comment_lines = []
        for line in lines:
            stripped = line.strip()
            if stripped.startswith(comment_prefix):
                content = stripped[len(comment_prefix):].strip()
                if content:  # å¿½ç•¥ç©ºæ³¨é‡Š
                    comment_lines.append(content)
            else:
                break  # é‡åˆ°éæ³¨é‡Šè¡Œå°±åœæ­¢
        
        if self.debug:
            print(f"  ğŸ“‹ æ‰¾åˆ° {len(comment_lines)} è¡Œè¿ç»­æ³¨é‡Š:")
            for i, line in enumerate(comment_lines, 1):
                print(f"     {i}: {line}")
        
        # è‡³å°‘éœ€è¦2è¡Œï¼ˆ1ä¸ªç›®å½• + æ–‡ä»¶åï¼‰
        if len(comment_lines) < 2:
            if self.debug:
                print(f"  âŒ æ³¨é‡Šè¡Œæ•°ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘2è¡Œï¼‰")
            return False
        
        # æœ€åä¸€è¡Œåº”è¯¥æ˜¯æ–‡ä»¶å
        last_line = comment_lines[-1]
        if not self._looks_like_filename(last_line):
            if self.debug:
                print(f"  âŒ æœ€åä¸€è¡Œä¸åƒæ–‡ä»¶å: {last_line}")
            return False
        
        # å‰é¢çš„è¡Œåº”è¯¥æ˜¯ç›®å½•ï¼ˆä¸èƒ½æ˜¯æ–‡ä»¶åï¼‰
        directories = comment_lines[:-1]
        for i, dir_name in enumerate(directories, 1):
            if self._looks_like_filename(dir_name):
                if self.debug:
                    print(f"  âŒ ç¬¬{i}è¡Œçœ‹èµ·æ¥åƒæ–‡ä»¶åè€Œä¸æ˜¯ç›®å½•: {dir_name}")
                return False
            if len(dir_name) < 2 or len(dir_name) > 100:
                if self.debug:
                    print(f"  âŒ ç¬¬{i}è¡Œé•¿åº¦ä¸åˆæ³•: {dir_name}")
                return False
        
        if self.debug:
            print(f"  âœ… éªŒè¯é€šè¿‡: {len(directories)} çº§ç›®å½•")
        
        return True
    
    def parse_comment(self, code: str) -> Tuple[Optional[List[str]], Optional[str]]:
        """
        è§£æä»£ç æ³¨é‡Šï¼Œæå–ç›®å½•ç»“æ„å’Œæ–‡ä»¶å
        
        Returns:
            (ç›®å½•åˆ—è¡¨, æ–‡ä»¶å) æˆ– (None, None)
        """
        if not code:
            return None, None
        
        lines = code.strip().split('\n')
        
        if len(lines) < 2:
            return None, None
        
        # æ£€æµ‹æ³¨é‡Šç±»å‹
        comment_prefix = None
        if lines[0].strip().startswith('//'):
            comment_prefix = '//'
        elif lines[0].strip().startswith('#'):
            comment_prefix = '#'
        else:
            return None, None
        
        # æ”¶é›†è¿ç»­çš„æ³¨é‡Šè¡Œ
        comment_lines = []
        for line in lines:
            stripped = line.strip()
            if stripped.startswith(comment_prefix):
                content = stripped[len(comment_prefix):].strip()
                if content:
                    comment_lines.append(content)
            else:
                break
        
        if len(comment_lines) < 2:
            return None, None
        
        # æœ€åä¸€è¡Œæ˜¯æ–‡ä»¶å
        filename = comment_lines[-1]
        if not self._looks_like_filename(filename):
            return None, None
        
        # å‰é¢çš„è¡Œæ˜¯ç›®å½•
        directories = comment_lines[:-1]
        
        # éªŒè¯æ‰€æœ‰ç›®å½•
        for dir_name in directories:
            if self._looks_like_filename(dir_name):
                return None, None
            if len(dir_name) < 2 or len(dir_name) > 100:
                return None, None
        
        return directories, filename
    
    def _looks_like_filename(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦çœ‹èµ·æ¥åƒæ–‡ä»¶å"""
        if not text:
            return True
        
        # å¦‚æœåŒ…å«æ–‡ä»¶æ‰©å±•å
        if re.search(r'\.(cpp|java|py|js|go|c|cs|rb|swift|kt|rs|php|ts|txt|md)$', text, re.IGNORECASE):
            return True
        
        # å¦‚æœä»¥æ•°å­—å’Œç‚¹å¼€å¤´ï¼ˆé¢˜å·ï¼‰
        if re.match(r'^\d+\.', text):
            return True
        
        # å¦‚æœåŒ…å«å¤šä¸ªè¿å­—ç¬¦ï¼ˆé€šå¸¸æ˜¯æ–‡ä»¶åæ ¼å¼ï¼‰
        if text.count('-') >= 2:
            return True
        
        return False
    
    def get_file_extension(self, lang: str) -> str:
        """æ ¹æ®è¯­è¨€è·å–æ–‡ä»¶æ‰©å±•å"""
        ext_map = {
            'cpp': 'cpp', 'c++': 'cpp', 'java': 'java',
            'python': 'py', 'python3': 'py',
            'javascript': 'js', 'typescript': 'ts',
            'golang': 'go', 'go': 'go', 'rust': 'rs',
            'c': 'c', 'csharp': 'cs', 'c#': 'cs',
            'ruby': 'rb', 'swift': 'swift', 'kotlin': 'kt',
            'scala': 'scala', 'php': 'php',
        }
        return ext_map.get(lang.lower(), 'txt')
    
    def sanitize_path_component(self, name: str) -> str:
        """æ¸…ç†è·¯å¾„ç»„ä»¶ï¼Œç§»é™¤éæ³•å­—ç¬¦"""
        if not name:
            return 'untitled'
        
        # ç§»é™¤ Windows å’Œ Unix éæ³•å­—ç¬¦
        name = re.sub(r'[<>:"/\\|?*\x00-\x1f]', '', name)
        name = name.strip('. \t\n\r')
        
        if not name:
            return 'untitled'
        
        if len(name) > 100:
            name = name[:100]
        
        return name
    
    def extract_title_from_filename(self, filename: str) -> str:
        """
        ä»æ³¨é‡Šä¸­çš„æ–‡ä»¶åæå–é¢˜ç›®åç§°
        ä¾‹å¦‚: "2841. å‡ ä¹å”¯ä¸€å­æ•°ç»„çš„æœ€å¤§å’Œ.cpp" -> "2841. å‡ ä¹å”¯ä¸€å­æ•°ç»„çš„æœ€å¤§å’Œ"
        """
        # å»æ‰æ–‡ä»¶æ‰©å±•å
        title = re.sub(r'\.(cpp|java|py|js|go|c|cs|rb|swift|kt|rs|php|ts)$', '', filename, flags=re.IGNORECASE)
        return title.strip()
    
    def delete_old_versions(self, dir_path: Path, title_pattern: str, current_file: Path):
        """
        åˆ é™¤åŒä¸€é¢˜ç›®çš„æ—§ç‰ˆæœ¬æ–‡ä»¶
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            title_pattern: é¢˜ç›®åç§°æ¨¡å¼ï¼ˆç”¨äºåŒ¹é…ï¼‰
            current_file: å½“å‰è¦ä¿å­˜çš„æ–‡ä»¶ï¼ˆä¸åˆ é™¤ï¼‰
        """
        if not dir_path.exists():
            return
        
        # æå–é¢˜å·ï¼ˆå¦‚æœæœ‰ï¼‰
        match = re.match(r'^(\d+)\.', title_pattern)
        if match:
            problem_id = match.group(1)
            # æŸ¥æ‰¾æ‰€æœ‰ä»¥ç›¸åŒé¢˜å·å¼€å¤´çš„æ–‡ä»¶
            deleted_count = 0
            for file in dir_path.glob(f"{problem_id}.*"):
                if file != current_file and file.is_file():
                    try:
                        file.unlink()
                        deleted_count += 1
                        if self.debug:
                            print(f"  ğŸ—‘ï¸  åˆ é™¤æ—§ç‰ˆæœ¬: {file.name}")
                    except Exception as e:
                        if self.debug:
                            print(f"  âš ï¸  åˆ é™¤å¤±è´¥ {file.name}: {e}")
            
            if deleted_count > 0 and not self.debug:
                print(f"  ğŸ—‘ï¸  åˆ é™¤äº† {deleted_count} ä¸ªæ—§ç‰ˆæœ¬")
    
    def save_submission(self, submission: Dict, detail: Dict) -> bool:
        """ä¿å­˜æäº¤åˆ°æœ¬åœ°æ–‡ä»¶"""
        code = detail.get('code', '')
        if not code:
            if self.debug:
                print(f"  âŒ æ²¡æœ‰ä»£ç å†…å®¹")
            return False
        
        directories, filename = self.parse_comment(code)
        
        if not directories or not filename:
            if self.debug:
                print(f"  âŠ˜ è·³è¿‡ï¼šæ²¡æœ‰æœ‰æ•ˆçš„ç›®å½•ç»“æ„æ³¨é‡Š")
            return False
        
        # æ¸…ç†æ‰€æœ‰ç›®å½•å
        safe_dirs = [self.sanitize_path_component(d) for d in directories]
        
        # æ„å»ºç›®å½•è·¯å¾„
        dir_path = Path(*safe_dirs)
        
        try:
            dir_path.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            print(f"  âŒ åˆ›å»ºç›®å½•å¤±è´¥ {dir_path}: {e}")
            return False
        
        # ä»æ³¨é‡Šä¸­çš„æ–‡ä»¶åæå–å®Œæ•´é¢˜ç›®åç§°ï¼ˆä¿ç•™é¢˜å·ï¼‰
        title = self.extract_title_from_filename(filename)
        safe_title = self.sanitize_path_component(title)
        
        # ä½¿ç”¨å®é™…çš„è¯­è¨€æ‰©å±•å
        lang = detail.get('lang', 'txt')
        ext = self.get_file_extension(lang)
        
        file_name = f"{safe_title}.{ext}"
        file_path = dir_path / file_name
        
        if self.debug:
            print(f"  ğŸ“‚ ç›®å½•ç»“æ„: {' / '.join(safe_dirs)}")
            print(f"  ğŸ“„ æ–‡ä»¶å: {file_name}")
            print(f"  ğŸ“ å®Œæ•´è·¯å¾„: {file_path}")
        
        # åˆ é™¤åŒä¸€é¢˜ç›®çš„æ—§ç‰ˆæœ¬
        self.delete_old_versions(dir_path, safe_title, file_path)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ£€æŸ¥å†…å®¹æ˜¯å¦ç›¸åŒ
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    existing_code = f.read()
                if existing_code == code:
                    print(f"  âŠ™ å·²å­˜åœ¨ï¼ˆå†…å®¹ç›¸åŒï¼‰: {file_path}")
                    return True
                else:
                    print(f"  â™»ï¸  æ›´æ–°æ–‡ä»¶: {file_path}")
            except:
                pass
        
        # ä¿å­˜æ–‡ä»¶
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(code)
            print(f"  âœ… å·²ä¿å­˜: {file_path}")
            return True
        except Exception as e:
            print(f"  âŒ ä¿å­˜å¤±è´¥ {file_path}: {e}")
            return False
    
    def sync(self):
        """æ‰§è¡ŒåŒæ­¥"""
        print("=" * 60)
        print("ğŸš€ å¼€å§‹åŒæ­¥ LeetCode æäº¤è®°å½•")
        print("=" * 60)
        
        submissions = self.get_ac_submissions()
        
        if not submissions:
            print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°ACæäº¤è®°å½•")
            return
        
        new_submissions = [
            sub for sub in submissions 
            if str(sub['id']) not in self.synced_ids
        ]
        
        if not new_submissions:
            print("âœ¨ æ²¡æœ‰æ–°çš„æäº¤éœ€è¦åŒæ­¥")
            return
        
        print(f"\nğŸ“¦ å…± {len(new_submissions)} æ¡æ–°æäº¤ï¼Œå¼€å§‹æ£€æŸ¥...")
        print("-" * 60)
        
        success_count = 0
        skipped_count = 0
        failed_count = 0
        
        for i, submission in enumerate(new_submissions, 1):
            sub_id = submission['id']
            title = submission.get('title', 'Unknown')
            timestamp = submission.get('timestamp')
            
            time_str = ""
            if timestamp:
                dt = datetime.fromtimestamp(int(timestamp), tz=timezone(timedelta(hours=8)))
                time_str = f" [{dt.strftime('%Y-%m-%d %H:%M')}]"
            
            print(f"\n[{i}/{len(new_submissions)}] {title}{time_str} (ID: {sub_id})")
            
            detail = self.get_submission_detail(sub_id)
            if not detail:
                failed_count += 1
                time.sleep(1)
                continue
            
            code = detail.get('code', '')
            if not self.has_valid_comment(code):
                print(f"  âŠ˜ è·³è¿‡ï¼šæ²¡æœ‰ç¬¦åˆæ ¼å¼çš„ç›®å½•ç»“æ„æ³¨é‡Š")
                skipped_count += 1
                self.synced_ids.add(str(sub_id))
                
                if i % 10 == 0:
                    self.save_synced_ids()
                
                time.sleep(0.5)
                continue
            
            if self.save_submission(submission, detail):
                self.synced_ids.add(str(sub_id))
                success_count += 1
            else:
                failed_count += 1
            
            if i % 10 == 0:
                self.save_synced_ids()
            
            time.sleep(1)
        
        self.save_synced_ids()
        
        print("\n" + "=" * 60)
        print(f"ğŸ‰ åŒæ­¥å®Œæˆï¼")
        print(f"  âœ… æˆåŠŸä¿å­˜: {success_count}")
        print(f"  âŠ˜ è·³è¿‡ï¼ˆæ— æ³¨é‡Šï¼‰: {skipped_count}")
        print(f"  âŒ å¤±è´¥: {failed_count}")
        print(f"  ğŸ“Š æ€»è®¡: {len(new_submissions)}")
        print("=" * 60)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ğŸ¤– åŒæ­¥ LeetCode AC æäº¤åˆ° GitHub',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python sync.py                                    # åŒæ­¥æ‰€æœ‰æ–°æäº¤
  python sync.py --after "2026-01-26 23:47"        # åªåŒæ­¥æŒ‡å®šæ—¶é—´ä¹‹åçš„æäº¤
  python sync.py --debug                            # è°ƒè¯•æ¨¡å¼
  python sync.py --force                            # å¼ºåˆ¶é‡æ–°åŒæ­¥æ‰€æœ‰æäº¤

æ³¨é‡Šæ ¼å¼è¦æ±‚:
  // ä¸€çº§ç›®å½•
  // äºŒçº§ç›®å½•
  // 2841. å‡ ä¹å”¯ä¸€å­æ•°ç»„çš„æœ€å¤§å’Œ.cpp
  
  âœ… æœ€åä¸€è¡Œå¿…é¡»æ˜¯æ–‡ä»¶åï¼ˆåŒ…å«é¢˜å·å’Œæ‰©å±•åï¼‰
  âœ… å‰é¢çš„è¡Œæ˜¯ç›®å½•å±‚çº§ï¼ˆæ”¯æŒä»»æ„å¤šçº§ï¼‰
  âœ… åŒä¸€é¢˜ç›®çš„æ–°æäº¤ä¼šè‡ªåŠ¨è¦†ç›–æ—§ç‰ˆæœ¬
        """
    )
    parser.add_argument('--after', type=str, help='åªåŒæ­¥æ­¤æ—¶é—´ä¹‹åçš„æäº¤ï¼Œæ ¼å¼: "2026-01-26 23:47" (åŒ—äº¬æ—¶é—´)')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºè¯¦ç»†çš„åŒ¹é…ä¿¡æ¯')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°åŒæ­¥æ‰€æœ‰æäº¤ï¼ˆå¿½ç•¥å·²åŒæ­¥è®°å½•ï¼‰')
    
    args = parser.parse_args()
    
    try:
        syncer = LeetCodeSyncer(sync_after=args.after, debug=args.debug)
        
        if args.force:
            print("âš ï¸  å¼ºåˆ¶æ¨¡å¼ï¼šå°†é‡æ–°åŒæ­¥æ‰€æœ‰æäº¤")
            syncer.synced_ids.clear()
        
        syncer.sync()
    except KeyboardInterrupt:
        print("\n\nâ¸ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜è¿›åº¦...")
        exit(0)
    except Exception as e:
        print(f"\nâŒ åŒæ­¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        exit(1)

if __name__ == '__main__':
    main()
